---
title: "Logistic Regression"
author: "Edneide Ramalho"
date: "`r format(Sys.time(), '%d de %B de %Y')`"
output: 
    html_document:
      highlight: textmate
      logo: logo.png
      theme: cerulean
      number_sections: yes
      toc: yes
      toc_float:
        collapsed: yes
        smooth_scroll: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Why you need logistic regression

-   When you have dichotomous variables, you can not use linear regression.

## Churn data

```{r}
#install.packages("devtools")
devtools::install_github("fstPackage/fst", ref = "develop")
```

```{r}
library(fst) # to read fst format
library(tidyverse)

# data
churn <- read_fst(
  "churn.fst",
  columns = NULL,
  from = 1,
  to = NULL,
  as.data.table = FALSE,
  old_format = FALSE
)
```

## Linear model

```{r}
mdl_churn_vs_recency_lm <- lm(has_churned ~ time_since_last_purchase, data = churn)
mdl_churn_vs_recency_lm
```

```{r}
coeffs <- coefficients(mdl_churn_vs_recency_lm)
intercept <- coeffs[1]
slope <- coeffs[2]
```

## Visualizing the linear model

```{r}
lm_plot <- ggplot(
  churn,
  aes(time_since_last_purchase, has_churned)
) +
  geom_point() +
  geom_abline(intercept = intercept,
              slope = slope)
lm_plot
```

## Zooming out

```{r}
lm_plot +
  xlim(-10, 10) +
  ylim(-0.2, 1.2)
```

## What is logistic regression?

-   Another type of generalized linear model.

-   Used when the response variable is logical.

-   The responses follow logistic (S-shaped) curve.

## Visualizing the logistic model

```{r}
glm_plot <- lm_plot +
  geom_smooth(
    method = "glm",
    se = FALSE,
    method.args = list(family = binomial)
  ) 
glm_plot
```

```{r}
glm_plot +
  xlim(-20, 20) +
  ylim(0, 1)
```

## Exercises

### Exploring the explanatory variables

When the response variable is logical, all the points lie on the y equals zero and y equals one lines, making it difficult to see what is happening. In the video, until you saw the trend line, it wasn't clear how the explanatory variable was distributed on each line. This can be solved with a histogram of the explanatory variable, faceted on the response.

You will use these histograms to get to know the financial services churn dataset seen in the video.

`churn` is available and `ggplot2` is loaded.

-   Using `churn`, plot `time_since_last_purchase` as a histogram with binwidth `0.25` faceted in a grid with `has_churned` on each row.

```{r}
ggplot(data = churn, aes(x = time_since_last_purchase)) +
  geom_histogram(binwidth = 0.25) +
  facet_grid(rows = vars(has_churned))
  
```

-   Redraw the plot with `time_since_first_purchase`. That is, using `churn`, plot `time_since_first_purchase` as a histogram with binwidth `0.25` faceted in a grid with `has_churned` on each row.

```{r}
ggplot(data = churn, aes(x = time_since_first_purchase)) +
  geom_histogram(binwidth = 0.25) +
  facet_grid(rows = vars(has_churned))
```

-   In the `time_since_the_last_purchase` plot, the distribution of churned customers was further right than the distribution of churned customers (churners typically has longer since their last purchase).

-   For `time_since_first_purchase` the opposite is true: churners have a shorter length relationship.

### **Visualizing linear and logistic models**

As with linear regressions, ggplot2 will draw model predictions for a logistic regression without you having to worry about the modeling code yourself. To see how the predictions differ for linear and logistic regressions, try drawing both trend lines side by side. Spoiler: you should see a linear (straight line) trend from the linear model, and a logistic (S-shaped) trend from the logistic model.

`churn` is available and `ggplot2` is loaded.

-   Using `churn` plot `has_churned` vs. `time_since_first_purchase` as a scatter plot, adding a red linear regression trend line (without a standard error ribbon).

```{r}
# Using churn plot has_churned vs. time_since_first_purchase
ggplot(churn, aes(x = time_since_first_purchase, y = has_churned)) +
  # Make it a scatter plot
  geom_point() +
  # Add an lm trend line, no std error ribbon, colored red
  geom_smooth(method = "lm", se = FALSE, color = "red")
```

-   Update the plot by adding a second trend line from logistic regression. (No standard error ribbon again).

```{r}
# Using churn plot has_churned vs. time_since_first_purchase
ggplot(churn, aes(x = time_since_first_purchase, y = has_churned)) +
  # Make it a scatter plot
  geom_point() +
  # Add an lm trend line, no std error ribbon, colored red
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  geom_smooth(method = "glm",
    se = FALSE,
    method.args = list(family = binomial))
```

### **Logistic regression with glm()**

Linear regression and logistic regression are special cases of a broader type of models called *generalized linear models* ("GLMs"). A linear regression makes the assumption that the residuals follow a Gaussian (normal) distribution. By contrast, a logistic regression assumes that residuals follow a binomial distribution.

Here, you'll model how the length of relationship with a customer affects churn.

`churn` is available.

-   Fit a logistic regression of `has_churned` versus `time_since_first_purchase` using the `churn` dataset. Assign to `mdl_churn_vs_relationship`.

```{r}
mdl_churn_vs_relationship <- glm(has_churned ~ time_since_first_purchase, data = churn, family = binomial)
mdl_churn_vs_relationship
```

# Predictions and odds ratio

-   Model:

```{r}
mdl_recency <- glm(
  has_churned ~ time_since_last_purchase,
  data = churn,
  family = "binomial"
)
```

-   Creating explanatory data:

```{r}
explanatory_data <- tibble(
  time_since_last_purchase = seq(-1, 6, 0.25)
)
```

-   Prediction:

```{r}
prediction_data <- explanatory_data %>% 
  dplyr::mutate(
    has_churned = predict(mdl_recency, explanatory_data, type = "response")
  )
```

# Quantifying logistic regression fit

## Adding point predictions

```{r}
plt_churn_vs_recency_base <- ggplot(data = churn, aes(x = time_since_last_purchase, y = has_churned)) + 
  geom_point() +
  geom_smooth(method = "glm",
    se = FALSE,
    method.args = list(family = binomial))
```

```{r}
plt_churn_vs_recency_base +
  geom_point(
    data = prediction_data,
    color = "blue"
  )
```

## Getting the most likely outcome

```{r}
prediction_data <- explanatory_data %>% 
  dplyr::mutate(
    has_churned = predict(mdl_recency, explanatory_data,
                          type = "response"),
    most_likely_outcome = round(has_churned)
  )
```

```{r}
plt_churn_vs_recency_base +
  geom_point(
    aes(y = most_likely_outcome),
    data = prediction_data,
    color = "green"
  )
```

-   For the most recently customers the most likely outcome is that they don't churn. Otherwise, the most likely outcome is that they will churn.

## Odds Ratios

-   *Odds ratio (OR)* é a probabilidade de que algo aconteça, dividido pela probabilidade de não acontecer.

$$
\text{OR} = \dfrac{\text{probabilidade}}{1 - \text{probabilidade}}
$$

## Calculando o *odds ratio*

```{r}
prediction_data <- explanatory_data %>% 
  dplyr::mutate(
    has_churned = predict(mdl_recency, explanatory_data, type = "response"),
    most_likely_response = round(has_churned),
    odds_ratio = has_churned / (1 - has_churned)
  )
```

## Visualizando odds ratio

```{r}
ggplot(
  prediction_data,
  aes(time_since_last_purchase, odds_ratio)
) +
  geom_line() +
  geom_hline(yintercept = 1, linetype = "dotted")
```

-   A linha pontilhada mostra OR = 1, que significa que a chance de churn é igual a de não-churn.

-   Na parte inferior esquerda, temos que OR \< 1, que significa que a chance de churn é menor do que de não-churn.

-   Na parte superior direita, a chance de churn é cerca de 5 vezes maior que não-churn.

## Exercícios

### **Probabilities**

There are four main ways of expressing the prediction from a logistic regression model -- we'll look at each of them over the next four exercises. Firstly, since the response variable is either "yes" or "no", you can make a prediction of the probability of a "yes". Here, you'll calculate and visualize these probabilities.

Three variables are available:

-   `mdl_churn_vs_relationship` is the logistic regression model of `has_churned` versus `time_since_first_purchase`.

-   `explanatory_data` is a data frame of explanatory values.

-   `plt_churn_vs_relationship` is a scatter plot of `has_churned` versus `time_since_first_purchase` with a smooth glm line.

`dplyr` is loaded.

##### 

-   Use the model, `mdl_churn_vs_relationship`, and the explanatory data, `explanatory_data`, to predict the probability of churning. Assign the predictions to the `has_churned` column of a data frame, `prediction_data`. *Remember to set the prediction* `type`.

```{r}
# Modelo
mdl_churn_vs_relationship <- glm(has_churned ~ time_since_first_purchase, data = churn, family = binomial)

# Dados exploratórios - para fazer predição
explanatory_data <- tibble(
  time_since_first_purchase = c(-1.50, -1.25, -1.00, -0.75, -0.50, -0.25,  0.00,  0.25,  0.50,  0.75,  1.00,  1.25, 1.50,  1.75,  2.00,  2.25,  2.50,  2.75,  3.00,  3.25,  3.50,  3.75,  4.00))

# Base de dados com Predição
prediction_data <- explanatory_data %>% 
  dplyr::mutate(
    has_churned = predict(mdl_churn_vs_relationship, explanatory_data, type = "response"))
```

-   Update the `plt_churn_vs_relationship` plot to add points from `prediction_data`, colored yellow.

```{r}
plt_churn_vs_relationship <- ggplot(data = churn, aes(x = time_since_first_purchase, y = has_churned)) +
  geom_point() +
  geom_smooth(method = "glm", se = FALSE, method.args = list(family = binomial))
plt_churn_vs_relationship
```

```{r}
# Update the plot
plt_churn_vs_relationship +
  # Add points from prediction_data, colored yellow, size 2
  geom_point(
    shape = 21,
    data = prediction_data,
    aes(y = has_churned),
    color = "white",
    fill = "yellow",
    stroke = 1.5
  )
```
